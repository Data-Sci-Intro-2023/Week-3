---
title: "Lesson 3.1: API Calls, Functions, and Iterations, Oh My!"
author: "Katie Willi"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

### Lesson Objectives

In this lesson we will be learning how to download data using application programming interfaces (APIs), and how to create our own functions. To fulfill these objectives we will be utilizing data from the National Park Service.

# What is an API?

An API is software that acts as an intermediary between a website's data warehouse (or server) and its users (or clients). As data scientists, APIs provide us a way to request clean and nicely-formatted data from websites that the server will then send to our local computers, all within our RStudio console! To work with APIs, we will need to use two new packages: `httr`, which allows us to communicate with the API's server, and `jsonlite`, which allows us to work with one of the most common API data formats, JSON. Let's go ahead and load in our packages for this lesson:

```{r}
# includes the tidyverse, rmarkdown, httr, and jsonlite
source("setup.R") 
```

## NPS "STATS" Visitation Data

To access the NPS API in R, we first need to explore its [API structure](https://irmaservices.nps.gov/). When working with APIs in RStudio, access commands are structured as URLs.

Fot this exercise let's say we are still interested in accessing park visitation data. From the main page of NPS's API Data Services website, go to *Stats Rest API - Documentation* (though not very intuitive, NPS's API calls its visitation data set "Stats"). Listed there you will see that all data associated with the "Stats" data set can be accessed using the base URL **https://irmaservices.nps.gov/v3/rest/stats**. From there, you can tack on additional html text to access two different data sets: **total/{year}** and **visitation**.

For starters, let's try accessing the **total/{year}**, which will give us total visitation across all NPS parks for a specified year:

[***https://irmaservices.nps.gov/v3/rest/stats/total/{YEAR}***](https://irmaservices.nps.gov/v3/rest/stats/total/%7BYEAR%7D){.uri}

The curly brackets {} signify locations in the URL that need to be updated by the user based on their specific needs. I'm curious about visitor use last year, so let's tweak the URL to access visitation data from 2022. In R, we can access this data using `httr`'s `GET()` function, replacing {YEAR} with 2022.

```{r}
raw_data <- httr::GET(url = "https://irmaservices.nps.gov/v3/rest/stats/total/2022")
# View raw_data:
# View(raw_data)
```

Viewing the data set as-is, you can see it is still not super human-readable. This is because data sent from APIs is typically packaged using JavaScript Object Notation (JSON).

To extract the data we want from this formatting, we will first need to use `httr`'s `content()` function. In this example, we want the data to be extracted as *text,* since this is a data table, and its encoding is listed as *UTF-8*. The encoding parameter can be found by opening our raw data set in our R console:

```{r}
raw_data

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 
```

Second, we need to transform this string of text, which is still in JSON formatting, into a data frame using `jsonlite`'s `fromJSON()`.

```{r}
# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)

head(final_data)
```

Hooray, you have now successfully pulled in an online data set using an API!

# Summary of workflow:

```{r, eval = FALSE}
raw_data <- httr::GET(url = "https://irmaservices.nps.gov/v3/rest/stats/total/2022")

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 

# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)
```

### Exercise #1

Using the code above, pull in total park visitation data for the year 1980.

```{r, eval = FALSE}
# ANSWER
raw_data <- httr::GET(url = "https://irmaservices.nps.gov/v3/rest/stats/total/1980")

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 

# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)
```

### Exercise #2

Now, let's explore the second data set in NPS's Stats: [**visitation**](https://irmaservices.nps.gov/v3/rest/Stats/help). This call pulls in monthly data for a specific park, across a specific time frame. Use your new API skills to pull in visitation data for Rocky Mountain National Park from 2010 through 2022. The unit code for Rocky Mountain National Park is ROMO. (Hint: an API URL can have multiple portions that need to be updated by the user.)

```{r}
# ANSWER:

raw_data <- httr::GET(url = "https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=ROMO&startMonth=01&startYear=2010&endMonth=12&endYear=2022")

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 

# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)
```

# What is a function?

You may find yourself thinking, "Wow, exercise 1 seemed like overkill!" Indeed, you had to run several lines of code that were nearly identical to what was shown upstream; the only thing you needed to change was *2022* to *1980*. This sort of coding is not recommended, as it is superfluous and can get out of hand fast when you need to run it across more than just two instances. Instead, we can write *functions* that combine many coding steps into just one command, and provide the option of changing just a minor part of that code base from one run to the next. Think `tidyr`'s `select()`, or the `GET()` function in `httr`: these are functions that have code under the hood that is not necessary to write out each time we use them. Instead, we just write out the function (e.g. `GET()`), and the necessary arguments within that function that tweak the code to fit it to our needs (e.g., `url = "https://irmaservices.nps.gov/v3/rest/stats/total/1980"`). 

## Functionize NPS "STATS" Pull

Let's make a function called `nps_visitation()` that pulls in NPS visitation data for a year of choice. To develop a function requires specific formatting:

```{r, eval = F}

NAME <- function(ARGUMENTS){
  
  ACTIONS
  
  return(OUTPUT)

  }

```

... where NAME is what we want to name the function; ARGUMENTS are the independent variables for the function; ACTIONS are the lines of code to perform within the function; and the OUTPUT is the object we want as the final outcome of running the function.

For `nps_visitation`, we will use our upstream code as the basis for our function, but with a few minor yet extremely important tweaks:

```{r}

nps_visitation <- function(year){

# pull in the data
raw_data <- httr::GET(url = 
                        # parse out year so that it can be chosen with the "year" argument, using paste0()
                        paste0("https://irmaservices.nps.gov/v3/rest/stats/total/", year))

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 

# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)

return(final_data)

}

```

In the above function, our first object, *raw_data*, now changes based on how we define our year argument. We accomplish this through `paste0()`, which takes listed objects, transforms them into characters (if they aren't already), and concatenates them into a single character string. For example:

```{r}
my_sentence <- "I need at least"
my_other_sentence <- "pints of ice cream a day"

paste0(my_sentence, " ", 08, " ", my_other_sentence, "!")
```

So, if we make year = 2022 in our `nps_visitation()` function, the year object becomes the number 2022, which makes the `paste0()` output "https://irmaservices.nps.gov/v3/rest/stats/total/2022", which subsequently pulls data for 2022. In other words, we can now pull visitation data for any year with just one line of code!

```{r}
original_pull <- nps_visitation(year = 2022)

exercise_pull <- nps_visitation(year = 1980)

new_pull <- nps_visitation(year = 1992)
```

### Exercise #3

Create a function to pull park-specific visitation data for a chosen park, across any time frame. All park codes can be found [here](https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx). (Hint 1: functions can have multiple arguments. Hint 2: what's the difference between `05` and `"05"`?)

```{r, eval = F, echo = F}
# ANSWER:

park_visitation <- function(park, start_month, start_year, end_month, end_year){
  
  raw_data <- httr::GET(url = paste0("https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=", park,
                                   "&startMonth=", start_month, 
                                   "&startYear=", start_year,
                                   "&endMonth=", end_month,
                                   "&endYear=", end_year))

# convert content to text
extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 

# parse text from JSON to data frame
final_data <- jsonlite::fromJSON(extracted_data)

return(final_data)

}

park_visitation("EVER","01","1990","12","2020")
```



